{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport zipfile\nimport requests\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\n# import torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom pathlib import Path\nimport json\nimport wandb\nimport time\nimport copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:37:48.272551Z","iopub.execute_input":"2025-04-17T19:37:48.273528Z","iopub.status.idle":"2025-04-17T19:37:57.782799Z","shell.execute_reply.started":"2025-04-17T19:37:48.273497Z","shell.execute_reply":"2025-04-17T19:37:57.781996Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"dataset_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\ndataset_zip_path = \"/kaggle/working/nature_12K.zip\"\ndataset_dir = \"nature_12K\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Parameters\nnum_classes = 10  # For iNaturalist (adjust if needed)\nbatch_size = 16\nnum_epochs = 10\nlearning_rate = 1e-3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:37:57.784002Z","iopub.execute_input":"2025-04-17T19:37:57.784249Z","iopub.status.idle":"2025-04-17T19:37:57.791968Z","shell.execute_reply.started":"2025-04-17T19:37:57.784228Z","shell.execute_reply":"2025-04-17T19:37:57.791106Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"if not os.path.exists(dataset_dir):\n    if not os.path.exists(dataset_zip_path):\n        print(\"Downloading iNaturalist-12K...\")\n        response = requests.get(dataset_url, stream=True)\n        total_size = int(response.headers.get('content-length', 0))\n        with open(dataset_zip_path, 'wb') as f, tqdm(\n            desc=dataset_zip_path,\n            total=total_size,\n            unit='iB',\n            unit_scale=True,\n            unit_divisor=1024,\n        ) as bar:\n            for data in response.iter_content(chunk_size=1024):\n                size = f.write(data)\n                bar.update(size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:37:57.792955Z","iopub.execute_input":"2025-04-17T19:37:57.793523Z","iopub.status.idle":"2025-04-17T19:38:46.710911Z","shell.execute_reply.started":"2025-04-17T19:37:57.793492Z","shell.execute_reply":"2025-04-17T19:38:46.710078Z"}},"outputs":[{"name":"stdout","text":"Downloading iNaturalist-12K...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/nature_12K.zip: 100%|██████████| 3.55G/3.55G [00:48<00:00, 78.3MiB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"if not os.path.exists(dataset_dir):\n    print(\"Extracting dataset...\")\n    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n        zip_ref.extractall(\".\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:38:46.712494Z","iopub.execute_input":"2025-04-17T19:38:46.712773Z","iopub.status.idle":"2025-04-17T19:39:17.663923Z","shell.execute_reply.started":"2025-04-17T19:38:46.712752Z","shell.execute_reply":"2025-04-17T19:39:17.662755Z"}},"outputs":[{"name":"stdout","text":"Extracting dataset...\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def prepare_datasets(data_dir, val_split=0.2, batch_size=32, image_size=(224, 224)):\n    data_dir = Path(data_dir)\n\n    # Define transforms (customize as needed)\n    transform = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),  # Converts to [0, 1] and CxHxW\n        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),  # Normalize RGB\n    ])\n\n    # Load training and testing datasets\n    full_train_dataset = ImageFolder(root=data_dir / \"train\", transform=transform)\n    test_dataset = ImageFolder(root=data_dir / \"val\", transform=transform)\n\n    # Create validation split from training set\n    val_size = int(val_split * len(full_train_dataset))\n    train_size = len(full_train_dataset) - val_size\n\n    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n\n    # Extract X and Y by iterating over DataLoader batches if needed\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n    # # Convert to X, Y tensors\n    # def extract_XY(loader):\n    #     for X, Y in loader:\n    #         return X, Y\n\n    # X_train, Y_train = extract_XY(train_loader)\n    # X_val, Y_val = extract_XY(val_loader)\n    # X_test, Y_test = extract_XY(test_loader)\n\n    return train_loader, val_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:39:17.665274Z","iopub.execute_input":"2025-04-17T19:39:17.665690Z","iopub.status.idle":"2025-04-17T19:39:17.674880Z","shell.execute_reply.started":"2025-04-17T19:39:17.665648Z","shell.execute_reply":"2025-04-17T19:39:17.674121Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# X_train, Y_train, X_val, Y_val, X_test, Y_test = prepare_datasets(\n#     data_dir='/kaggle/working/inaturalist_12K', val_split=0.2, batch_size=64, image_size=(224, 224)\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader, val_loader, test_loader = prepare_datasets(\n    data_dir='/kaggle/working/inaturalist_12K', val_split=0.2, batch_size=64, image_size=(224, 224)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:39:17.676046Z","iopub.execute_input":"2025-04-17T19:39:17.676974Z","iopub.status.idle":"2025-04-17T19:39:17.781244Z","shell.execute_reply.started":"2025-04-17T19:39:17.676941Z","shell.execute_reply":"2025-04-17T19:39:17.780465Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torchvision.models as models\n\nmodel = models.resnet50(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)  # Replace last layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:39:17.782210Z","iopub.execute_input":"2025-04-17T19:39:17.782455Z","iopub.status.idle":"2025-04-17T19:39:19.732163Z","shell.execute_reply.started":"2025-04-17T19:39:17.782435Z","shell.execute_reply":"2025-04-17T19:39:19.731107Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 121MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Freeze all layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace the final layer (fc) for 10-class classification\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_classes)\n\n# Only the final layer's parameters will be updated\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:39:19.733297Z","iopub.execute_input":"2025-04-17T19:39:19.733992Z","iopub.status.idle":"2025-04-17T19:39:19.749038Z","shell.execute_reply.started":"2025-04-17T19:39:19.733956Z","shell.execute_reply":"2025-04-17T19:39:19.748132Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Training loop\ndef train_model(model, criterion, optimizer, num_epochs=10):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n                dataloader = train_loader\n            else:\n                model.eval()\n                dataloader = val_loader\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloader.dataset)\n            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n\n            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    print(f\"Best Validation Acc: {best_acc:.4f}\")\n    model.load_state_dict(best_model_wts)\n    return model\n\n# Run training\nmodel = train_model(model, criterion, optimizer, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:39:19.750249Z","iopub.execute_input":"2025-04-17T19:39:19.750563Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.1860 Acc: 0.6246\nVal Loss: 0.9322 Acc: 0.7074\nEpoch 2/10\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}