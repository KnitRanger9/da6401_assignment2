{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:08.836719Z","iopub.execute_input":"2025-04-15T20:01:08.836982Z","iopub.status.idle":"2025-04-15T20:01:12.971925Z","shell.execute_reply.started":"2025-04-15T20:01:08.836962Z","shell.execute_reply":"2025-04-15T20:01:12.971165Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport numpy as np\nimport zipfile\nimport requests\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\n# import torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom pathlib import Path\nimport json\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:00:58.590774Z","iopub.execute_input":"2025-04-15T20:00:58.591376Z","iopub.status.idle":"2025-04-15T20:01:08.835702Z","shell.execute_reply.started":"2025-04-15T20:00:58.591354Z","shell.execute_reply":"2025-04-15T20:01:08.835114Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\ndataset_zip_path = \"/kaggle/working/nature_12K.zip\"\ndataset_dir = \"nature_12K\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:12.973589Z","iopub.execute_input":"2025-04-15T20:01:12.973813Z","iopub.status.idle":"2025-04-15T20:01:12.978009Z","shell.execute_reply.started":"2025-04-15T20:01:12.973793Z","shell.execute_reply":"2025-04-15T20:01:12.977284Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"if not os.path.exists(dataset_dir):\n    if not os.path.exists(dataset_zip_path):\n        print(\"Downloading iNaturalist-12K...\")\n        response = requests.get(dataset_url, stream=True)\n        total_size = int(response.headers.get('content-length', 0))\n        with open(dataset_zip_path, 'wb') as f, tqdm(\n            desc=dataset_zip_path,\n            total=total_size,\n            unit='iB',\n            unit_scale=True,\n            unit_divisor=1024,\n        ) as bar:\n            for data in response.iter_content(chunk_size=1024):\n                size = f.write(data)\n                bar.update(size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:12.978858Z","iopub.execute_input":"2025-04-15T20:01:12.979134Z","iopub.status.idle":"2025-04-15T20:02:43.326143Z","shell.execute_reply.started":"2025-04-15T20:01:12.979112Z","shell.execute_reply":"2025-04-15T20:02:43.325268Z"}},"outputs":[{"name":"stdout","text":"Downloading iNaturalist-12K...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/nature_12K.zip: 100%|██████████| 3.55G/3.55G [01:30<00:00, 42.3MiB/s] \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"if not os.path.exists(dataset_dir):\n    print(\"Extracting dataset...\")\n    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n        zip_ref.extractall(\".\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:02:43.327796Z","iopub.execute_input":"2025-04-15T20:02:43.328045Z","iopub.status.idle":"2025-04-15T20:02:57.405985Z","shell.execute_reply.started":"2025-04-15T20:02:43.328017Z","shell.execute_reply":"2025-04-15T20:02:57.405472Z"}},"outputs":[{"name":"stdout","text":"Extracting dataset...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def prepare_datasets(data_dir, val_split=0.2, batch_size=32, image_size=(224, 224)):\n    data_dir = Path(data_dir)\n\n    # Define transforms (customize as needed)\n    transform = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),  # Converts to [0, 1] and CxHxW\n        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),  # Normalize RGB\n    ])\n\n    # Load training and testing datasets\n    full_train_dataset = ImageFolder(root=data_dir / \"train\", transform=transform)\n    test_dataset = ImageFolder(root=data_dir / \"val\", transform=transform)\n\n    # Create validation split from training set\n    val_size = int(val_split * len(full_train_dataset))\n    train_size = len(full_train_dataset) - val_size\n\n    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n\n    # Extract X and Y by iterating over DataLoader batches if needed\n    train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n\n    # Convert to X, Y tensors\n    def extract_XY(loader):\n        for X, Y in loader:\n            return X, Y\n\n    X_train, Y_train = extract_XY(train_loader)\n    X_val, Y_val = extract_XY(val_loader)\n    X_test, Y_test = extract_XY(test_loader)\n\n    return X_train, Y_train, X_val, Y_val, X_test, Y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:02:57.406547Z","iopub.execute_input":"2025-04-15T20:02:57.406781Z","iopub.status.idle":"2025-04-15T20:02:57.414866Z","shell.execute_reply.started":"2025-04-15T20:02:57.406759Z","shell.execute_reply":"2025-04-15T20:02:57.413882Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# dataset_dir = \"/kaggle/working/inaturalist_12K\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:10:03.109108Z","iopub.execute_input":"2025-04-15T16:10:03.109438Z","iopub.status.idle":"2025-04-15T16:10:03.699454Z","shell.execute_reply.started":"2025-04-15T16:10:03.109416Z","shell.execute_reply":"2025-04-15T16:10:03.698531Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"X_train, Y_train, X_val, Y_val, X_test, Y_test = prepare_datasets(\n    data_dir='/kaggle/working/inaturalist_12K', val_split=0.2, batch_size=64, image_size=(224, 224)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:02:57.415658Z","iopub.execute_input":"2025-04-15T20:02:57.416305Z","iopub.status.idle":"2025-04-15T20:04:55.066081Z","shell.execute_reply.started":"2025-04-15T20:02:57.416282Z","shell.execute_reply":"2025-04-15T20:04:55.064062Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2071112055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_train, Y_train, X_val, Y_val, X_test, Y_test = prepare_datasets(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/working/inaturalist_12K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n","\u001b[0;32m/tmp/ipykernel_31/257089207.py\u001b[0m in \u001b[0;36mprepare_datasets\u001b[0;34m(data_dir, val_split, batch_size, image_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_XY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_XY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_XY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/257089207.py\u001b[0m in \u001b[0;36mextract_XY\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Convert to X, Y tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_XY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 )\n\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m     def reduce(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"print(X_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:04:55.066926Z","iopub.status.idle":"2025-04-15T20:04:55.067365Z","shell.execute_reply.started":"2025-04-15T20:04:55.067159Z","shell.execute_reply":"2025-04-15T20:04:55.067172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part A\n### Question 1\n\nBuild a small CNN model consisting of 5 convolution layers. Each convolution layer would be followed by an activation and a max-pooling layer.\n\nAfter 5 such conv-activation-maxpool blocks, you should have one dense layer followed by the output layer containing 10 neurons. The input layer should be compatible with the images in the iNaturalist dataset dataset.\nThe code should be flexible such that the number of filters, size of filters, and activation function of the convolution layers and dense layers can be changed. You should also be able to change the number of neurons in the dense layer.","metadata":{}},{"cell_type":"code","source":"api_key = \"7040d84a3ed65a967eb3389dd6fe774b418576ed\" \nwandb.login(key=api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:05:06.895504Z","iopub.execute_input":"2025-04-15T20:05:06.895818Z","iopub.status.idle":"2025-04-15T20:05:13.179830Z","shell.execute_reply.started":"2025-04-15T20:05:06.895796Z","shell.execute_reply":"2025-04-15T20:05:13.179288Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m004\u001b[0m (\u001b[33mda24m004-iitmaana\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"class FlexibleCNN(nn.Module):\n    def __init__(self, \n                 num_filters=32,  # number of filters in each conv layer\n                 filter_size=3,   # size of filters (k x k)\n                 activation='relu',  # activation function\n                 dense_neurons=512,  # number of neurons in dense layer\n                 input_channels=3,   # RGB images\n                 num_classes=10,    # number of output classes\n                 use_batch_norm=True,  # whether to use batch normalization\n                 dropout_rate=0.2):  # dropout rate\n        super(FlexibleCNN, self).__init__()\n        \n        # Store parameters for calculations\n        self.num_filters = num_filters\n        self.filter_size = filter_size\n        self.dense_neurons = dense_neurons\n        self.use_batch_norm = use_batch_norm\n        self.dropout_rate = dropout_rate\n        \n        # Choose activation function\n        if activation.lower() == 'relu':\n            self.activation = nn.ReLU()\n        elif activation.lower() == 'leakyrelu':\n            self.activation = nn.LeakyReLU()\n        elif activation.lower() == 'gelu':\n            self.activation = nn.GELU()\n        elif activation.lower() == 'silu':\n            self.activation = nn.SiLU()\n        elif activation.lower() == 'mish':\n            self.activation = nn.Mish()\n        else:\n            raise ValueError(f\"Unsupported activation function: {activation}\")\n        \n        # Create 5 conv-activation-maxpool blocks\n        self.conv_blocks = nn.ModuleList()\n        in_channels = input_channels\n        \n        for _ in range(5):\n            block = []\n            # Conv layer\n            block.append(nn.Conv2d(in_channels, num_filters, filter_size, padding=filter_size//2))\n            \n            # Batch normalization if enabled\n            if use_batch_norm:\n                block.append(nn.BatchNorm2d(num_filters))\n            \n            # Activation\n            block.append(self.activation)\n            \n            # Max pooling\n            block.append(nn.MaxPool2d(2, 2))\n            \n            # Dropout after pooling\n            block.append(nn.Dropout2d(dropout_rate))\n            \n            self.conv_blocks.extend(block)\n            in_channels = num_filters\n        \n        # Calculate the size of the flattened features after conv blocks\n        # Assuming input size of 224x224 (standard for iNaturalist)\n        self.flattened_size = num_filters * (224 // (2**5)) * (224 // (2**5))\n        \n        # Dense layers\n        self.dense = nn.Sequential(\n            nn.Linear(self.flattened_size, dense_neurons),\n            self.activation,\n            nn.Dropout(dropout_rate),  # Dropout before final layer\n            nn.Linear(dense_neurons, num_classes)\n        )\n    \n    def forward(self, x):\n        for block in self.conv_blocks:\n            x = block(x)\n        x = x.view(x.size(0), -1)\n        x = self.dense(x)\n        return x\n    \n    def get_computations(self):\n        \"\"\"Calculate total number of computations\"\"\"\n        # Computations in conv layers\n        conv_computations = 0\n        input_size = 224\n        in_channels = 3\n        \n        for i in range(5):\n            # Each conv layer\n            conv_computations += (input_size * input_size * in_channels * \n                                self.num_filters * self.filter_size * self.filter_size)\n            # Each maxpool reduces size by 2\n            input_size = input_size // 2\n            in_channels = self.num_filters\n        \n        # Computations in dense layers\n        dense_computations = (self.flattened_size * self.dense_neurons +  # first dense layer\n                            self.dense_neurons * 10)  # output layer\n        \n        return conv_computations + dense_computations\n    \n    def get_parameters(self):\n        \"\"\"Calculate total number of parameters\"\"\"\n        # Parameters in conv layers\n        conv_params = 0\n        in_channels = 3\n        \n        for _ in range(5):\n            # Each conv layer has (filter_size * filter_size * in_channels + 1) * num_filters parameters\n            conv_params += (self.filter_size * self.filter_size * in_channels + 1) * self.num_filters\n            # Batch norm parameters if enabled\n            if self.use_batch_norm:\n                conv_params += 2 * self.num_filters  # gamma and beta for each channel\n            in_channels = self.num_filters\n        \n        # Parameters in dense layers\n        dense_params = (self.flattened_size * self.dense_neurons + self.dense_neurons +  # first dense layer\n                       self.dense_neurons * 10 + 10)  # output layer\n        \n        return conv_params + dense_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:05:13.180989Z","iopub.execute_input":"2025-04-15T20:05:13.181587Z","iopub.status.idle":"2025-04-15T20:05:13.192058Z","shell.execute_reply.started":"2025-04-15T20:05:13.181569Z","shell.execute_reply":"2025-04-15T20:05:13.191342Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def train(config=None):\n    # Initialize wandb\n    with wandb.init(config=config):\n        config = wandb.config\n        \n        # Set random seed for reproducibility\n        torch.manual_seed(config.seed)\n        np.random.seed(config.seed)\n        \n        # Data augmentation and normalization\n        train_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        val_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        # Load dataset\n        train_dataset = datasets.ImageFolder(\n            root='/kaggle/working/inaturalist_12K/train',\n            transform=train_transform\n        )\n        \n        # Split into train and validation\n        train_size = int(0.8 * len(train_dataset))\n        val_size = len(train_dataset) - train_size\n        \n        # Use stratified split to maintain class balance\n        train_indices, val_indices = train_test_split(\n            list(range(len(train_dataset))),\n            test_size=0.2,\n            stratify=train_dataset.targets,\n            random_state=config.seed\n        )\n        \n        train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n        val_subset = torch.utils.data.Subset(train_dataset, val_indices)\n        \n        train_loader = DataLoader(\n            train_subset,\n            batch_size=config.batch_size,\n            shuffle=True,\n            num_workers=4\n        )\n        \n        val_loader = DataLoader(\n            val_subset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=4\n        )\n        \n        # Initialize model\n        model = FlexibleCNN(\n            num_filters=config.num_filters,\n            filter_size=config.filter_size,\n            activation=config.activation,\n            dense_neurons=config.dense_neurons,\n            use_batch_norm=config.use_batch_norm,\n            dropout_rate=config.dropout_rate\n        )\n        \n        # Move model to GPU if available\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model = model.to(device)\n        \n        # Loss function and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n        \n        # Training loop\n        best_val_acc = 0\n        best_config = None\n        \n        for epoch in range(config.epochs):\n            # Training phase\n            model.train()\n            train_loss = 0\n            train_correct = 0\n            train_total = 0\n            \n            for batch_idx, (inputs, targets) in enumerate(train_loader):\n                inputs, targets = inputs.to(device), targets.to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                \n                train_loss += loss.item()\n                _, predicted = outputs.max(1)\n                train_total += targets.size(0)\n                train_correct += predicted.eq(targets).sum().item()\n                \n                if batch_idx % 100 == 0:\n                    print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n            \n            train_acc = 100. * train_correct / train_total\n            \n            # Validation phase\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            \n            with torch.no_grad():\n                for inputs, targets in val_loader:\n                    inputs, targets = inputs.to(device), targets.to(device)\n                    outputs = model(inputs)\n                    loss = criterion(outputs, targets)\n                    \n                    val_loss += loss.item()\n                    _, predicted = outputs.max(1)\n                    val_total += targets.size(0)\n                    val_correct += predicted.eq(targets).sum().item()\n            \n            val_acc = 100. * val_correct / val_total\n            \n            # Log metrics to wandb\n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": train_loss / len(train_loader),\n                \"train_acc\": train_acc,\n                \"val_loss\": val_loss / len(val_loader),\n                \"val_acc\": val_acc\n            })\n            \n            # Save best model\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model.state_dict(), 'best_model.pth')\n            \n            print(f'Epoch: {epoch}, Train Loss: {train_loss/len(train_loader):.4f}, '\n                  f'Train Acc: {train_acc:.2f}%, Val Loss: {val_loss/len(val_loader):.4f}, '\n                  f'Val Acc: {val_acc:.2f}%')\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:05:13.330215Z","iopub.execute_input":"2025-04-15T20:05:13.330469Z","iopub.status.idle":"2025-04-15T20:05:13.343656Z","shell.execute_reply.started":"2025-04-15T20:05:13.330452Z","shell.execute_reply":"2025-04-15T20:05:13.342820Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n# Define sweep configuration\nsweep_config = {\n    'method': 'bayes',  # Use Bayesian optimization\n    'metric': {\n        'name': 'val_acc',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'num_filters': {\n            'values': [32, 64, 128]\n        },\n        'filter_size': {\n            'values': [3, 5]\n        },\n        'activation': {\n            'values': ['relu', 'gelu', 'silu', 'mish']\n        },\n        'dense_neurons': {\n            'values': [256, 512, 1024]\n        },\n        'learning_rate': {\n            'min': 1e-4,\n            'max': 1e-2\n        },\n        'batch_size': {\n            'values': [32, 64, 128]\n        },\n        'use_batch_norm': {\n            'values': [True, False]\n        },\n        'dropout_rate': {\n            'values': [0.2, 0.3, 0.4]\n        },\n        'epochs': {\n            'value': 5\n        },\n        'seed': {\n            'value': 42\n        }\n    }\n}\n\n# Initialize sweep\nsweep_id = wandb.sweep(sweep_config, project=\"inaturalist-cnn-sweep\")\n\n# Run sweep\nwandb.agent(sweep_id, train, count=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:05:17.563424Z","iopub.execute_input":"2025-04-15T20:05:17.564003Z","iopub.status.idle":"2025-04-15T20:15:30.711596Z","shell.execute_reply.started":"2025-04-15T20:05:17.563979Z","shell.execute_reply":"2025-04-15T20:15:30.710928Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ohumz2ah\nSweep URL: https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n6orkbv3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011060816138786856\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250415_200524-n6orkbv3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/n6orkbv3' target=\"_blank\">desert-sweep-1</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/n6orkbv3' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/n6orkbv3</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.2873\nEpoch: 0, Batch: 100, Loss: 2.3042\nEpoch: 0, Batch: 200, Loss: 2.4302\nEpoch: 0, Train Loss: 2.2917, Train Acc: 11.80%, Val Loss: 2.2303, Val Acc: 15.95%\nEpoch: 1, Batch: 0, Loss: 2.2839\nEpoch: 1, Batch: 100, Loss: 2.2084\nEpoch: 1, Batch: 200, Loss: 2.3020\nEpoch: 1, Train Loss: 2.2387, Train Acc: 16.71%, Val Loss: 2.1943, Val Acc: 20.50%\nEpoch: 2, Batch: 0, Loss: 2.0512\nEpoch: 2, Batch: 100, Loss: 2.2482\nEpoch: 2, Batch: 200, Loss: 2.3688\nEpoch: 2, Train Loss: 2.1968, Train Acc: 18.85%, Val Loss: 2.1451, Val Acc: 22.55%\nEpoch: 3, Batch: 0, Loss: 2.1231\nEpoch: 3, Batch: 100, Loss: 2.0208\nEpoch: 3, Batch: 200, Loss: 2.1466\nEpoch: 3, Train Loss: 2.1715, Train Acc: 20.63%, Val Loss: 2.1297, Val Acc: 21.25%\nEpoch: 4, Batch: 0, Loss: 2.0204\nEpoch: 4, Batch: 100, Loss: 2.1920\nEpoch: 4, Batch: 200, Loss: 2.0479\nEpoch: 4, Train Loss: 2.1495, Train Acc: 21.23%, Val Loss: 2.1020, Val Acc: 23.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▅▆██</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_acc</td><td>▁▅▇▆█</td></tr><tr><td>val_loss</td><td>█▆▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>21.22765</td></tr><tr><td>train_loss</td><td>2.14946</td></tr><tr><td>val_acc</td><td>23.5</td></tr><tr><td>val_loss</td><td>2.10196</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">desert-sweep-1</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/n6orkbv3' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/n6orkbv3</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250415_200524-n6orkbv3/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6y4m9n28 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0064928089332368264\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250415_201017-6y4m9n28</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6y4m9n28' target=\"_blank\">mild-sweep-2</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/ohumz2ah</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6y4m9n28' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6y4m9n28</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3722\nEpoch: 0, Batch: 100, Loss: 2.3137\nEpoch: 0, Train Loss: 2.5559, Train Acc: 10.44%, Val Loss: 2.2965, Val Acc: 10.20%\nEpoch: 1, Batch: 0, Loss: 2.3852\nEpoch: 1, Batch: 100, Loss: 2.3203\nEpoch: 1, Train Loss: 2.3200, Train Acc: 9.94%, Val Loss: 2.3025, Val Acc: 10.05%\nEpoch: 2, Batch: 0, Loss: 2.3032\nEpoch: 2, Batch: 100, Loss: 2.3041\nEpoch: 2, Train Loss: 2.3079, Train Acc: 10.08%, Val Loss: 2.3012, Val Acc: 12.15%\nEpoch: 3, Batch: 0, Loss: 2.2972\nEpoch: 3, Batch: 100, Loss: 2.4603\nEpoch: 3, Train Loss: 2.3114, Train Acc: 9.68%, Val Loss: 2.3027, Val Acc: 10.00%\nEpoch: 4, Batch: 0, Loss: 2.3068\nEpoch: 4, Batch: 100, Loss: 2.3064\nEpoch: 4, Train Loss: 2.3134, Train Acc: 10.11%, Val Loss: 2.3027, Val Acc: 10.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>█▃▅▁▅</td></tr><tr><td>train_loss</td><td>█▁▁▁▁</td></tr><tr><td>val_acc</td><td>▂▁█▁▁</td></tr><tr><td>val_loss</td><td>▁█▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>10.11376</td></tr><tr><td>train_loss</td><td>2.31337</td></tr><tr><td>val_acc</td><td>10</td></tr><tr><td>val_loss</td><td>2.30273</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">mild-sweep-2</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6y4m9n28' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6y4m9n28</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250415_201017-6y4m9n28/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qg12fchy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006884890630348681\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# /kaggle/working/inaturalist_12K/train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:13:41.289828Z","iopub.execute_input":"2025-04-15T16:13:41.290214Z","iopub.status.idle":"2025-04-15T16:13:41.294748Z","shell.execute_reply.started":"2025-04-15T16:13:41.290187Z","shell.execute_reply":"2025-04-15T16:13:41.293842Z"}},"outputs":[],"execution_count":39}]}