{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:08.836719Z","iopub.execute_input":"2025-04-15T20:01:08.836982Z","iopub.status.idle":"2025-04-15T20:01:12.971925Z","shell.execute_reply.started":"2025-04-15T20:01:08.836962Z","shell.execute_reply":"2025-04-15T20:01:12.971165Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport numpy as np\nimport zipfile\nimport requests\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\n# import torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom pathlib import Path\nimport json\nimport wandb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\ndataset_zip_path = \"/kaggle/working/nature_12K.zip\"\ndataset_dir = \"nature_12K\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not os.path.exists(dataset_dir):\n    if not os.path.exists(dataset_zip_path):\n        print(\"Downloading iNaturalist-12K...\")\n        response = requests.get(dataset_url, stream=True)\n        total_size = int(response.headers.get('content-length', 0))\n        with open(dataset_zip_path, 'wb') as f, tqdm(\n            desc=dataset_zip_path,\n            total=total_size,\n            unit='iB',\n            unit_scale=True,\n            unit_divisor=1024,\n        ) as bar:\n            for data in response.iter_content(chunk_size=1024):\n                size = f.write(data)\n                bar.update(size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not os.path.exists(dataset_dir):\n    print(\"Extracting dataset...\")\n    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n        zip_ref.extractall(\".\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_datasets(data_dir, val_split=0.2, batch_size=32, image_size=(224, 224)):\n    data_dir = Path(data_dir)\n\n    # Define transforms (customize as needed)\n    transform = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),  # Converts to [0, 1] and CxHxW\n        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),  # Normalize RGB\n    ])\n\n    # Load training and testing datasets\n    full_train_dataset = ImageFolder(root=data_dir / \"train\", transform=transform)\n    test_dataset = ImageFolder(root=data_dir / \"val\", transform=transform)\n\n    # Create validation split from training set\n    val_size = int(val_split * len(full_train_dataset))\n    train_size = len(full_train_dataset) - val_size\n\n    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n\n    # Extract X and Y by iterating over DataLoader batches if needed\n    train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n\n    # Convert to X, Y tensors\n    def extract_XY(loader):\n        for X, Y in loader:\n            return X, Y\n\n    X_train, Y_train = extract_XY(train_loader)\n    X_val, Y_val = extract_XY(val_loader)\n    X_test, Y_test = extract_XY(test_loader)\n\n    return X_train, Y_train, X_val, Y_val, X_test, Y_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dataset_dir = \"/kaggle/working/inaturalist_12K\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:10:03.109108Z","iopub.execute_input":"2025-04-15T16:10:03.109438Z","iopub.status.idle":"2025-04-15T16:10:03.699454Z","shell.execute_reply.started":"2025-04-15T16:10:03.109416Z","shell.execute_reply":"2025-04-15T16:10:03.698531Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# X_train, Y_train, X_val, Y_val, X_test, Y_test = prepare_datasets(\n#     data_dir='/kaggle/working/inaturalist_12K', val_split=0.2, batch_size=64, image_size=(224, 224)\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(X_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:04:55.066926Z","iopub.status.idle":"2025-04-15T20:04:55.067365Z","shell.execute_reply.started":"2025-04-15T20:04:55.067159Z","shell.execute_reply":"2025-04-15T20:04:55.067172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part A\n### Question 1\n\nBuild a small CNN model consisting of 5 convolution layers. Each convolution layer would be followed by an activation and a max-pooling layer.\n\nAfter 5 such conv-activation-maxpool blocks, you should have one dense layer followed by the output layer containing 10 neurons. The input layer should be compatible with the images in the iNaturalist dataset dataset.\nThe code should be flexible such that the number of filters, size of filters, and activation function of the convolution layers and dense layers can be changed. You should also be able to change the number of neurons in the dense layer.","metadata":{}},{"cell_type":"code","source":"api_key = \"7040d84a3ed65a967eb3389dd6fe774b418576ed\" \nwandb.login(key=api_key)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FlexibleCNN(nn.Module):\n    def __init__(self, \n                 num_filters=32,  # number of filters in each conv layer\n                 filter_size=3,   # size of filters (k x k)\n                 activation='relu',  # activation function\n                 dense_neurons=512,  # number of neurons in dense layer\n                 input_channels=3,   # RGB images\n                 num_classes=10,    # number of output classes\n                 use_batch_norm=True,  # whether to use batch normalization\n                 dropout_rate=0.2):  # dropout rate\n        super(FlexibleCNN, self).__init__()\n        \n        # Store parameters for calculations\n        self.num_filters = num_filters\n        self.filter_size = filter_size\n        self.dense_neurons = dense_neurons\n        self.use_batch_norm = use_batch_norm\n        self.dropout_rate = dropout_rate\n        \n        # Choose activation function\n        if activation.lower() == 'relu':\n            self.activation = nn.ReLU()\n        elif activation.lower() == 'leakyrelu':\n            self.activation = nn.LeakyReLU()\n        elif activation.lower() == 'gelu':\n            self.activation = nn.GELU()\n        elif activation.lower() == 'silu':\n            self.activation = nn.SiLU()\n        elif activation.lower() == 'mish':\n            self.activation = nn.Mish()\n        else:\n            raise ValueError(f\"Unsupported activation function: {activation}\")\n        \n        # Create 5 conv-activation-maxpool blocks\n        self.conv_blocks = nn.ModuleList()\n        in_channels = input_channels\n        \n        for _ in range(5):\n            block = []\n            # Conv layer\n            block.append(nn.Conv2d(in_channels, num_filters, filter_size, padding=filter_size//2))\n            \n            # Batch normalization if enabled\n            if use_batch_norm:\n                block.append(nn.BatchNorm2d(num_filters))\n            \n            # Activation\n            block.append(self.activation)\n            \n            # Max pooling\n            block.append(nn.MaxPool2d(2, 2))\n            \n            # Dropout after pooling\n            block.append(nn.Dropout2d(dropout_rate))\n            \n            self.conv_blocks.extend(block)\n            in_channels = num_filters\n        \n        # Calculate the size of the flattened features after conv blocks\n        # Assuming input size of 224x224 (standard for iNaturalist)\n        self.flattened_size = num_filters * (224 // (2**5)) * (224 // (2**5))\n        \n        # Dense layers\n        self.dense = nn.Sequential(\n            nn.Linear(self.flattened_size, dense_neurons),\n            self.activation,\n            nn.Dropout(dropout_rate),  # Dropout before final layer\n            nn.Linear(dense_neurons, num_classes)\n        )\n    \n    def forward(self, x):\n        for block in self.conv_blocks:\n            x = block(x)\n        x = x.view(x.size(0), -1)\n        x = self.dense(x)\n        return x\n    \n    def get_computations(self):\n        \"\"\"Calculate total number of computations\"\"\"\n        # Computations in conv layers\n        conv_computations = 0\n        input_size = 224\n        in_channels = 3\n        \n        for i in range(5):\n            # Each conv layer\n            conv_computations += (input_size * input_size * in_channels * \n                                self.num_filters * self.filter_size * self.filter_size)\n            # Each maxpool reduces size by 2\n            input_size = input_size // 2\n            in_channels = self.num_filters\n        \n        # Computations in dense layers\n        dense_computations = (self.flattened_size * self.dense_neurons +  # first dense layer\n                            self.dense_neurons * 10)  # output layer\n        \n        return conv_computations + dense_computations\n    \n    def get_parameters(self):\n        \"\"\"Calculate total number of parameters\"\"\"\n        # Parameters in conv layers\n        conv_params = 0\n        in_channels = 3\n        \n        for _ in range(5):\n            # Each conv layer has (filter_size * filter_size * in_channels + 1) * num_filters parameters\n            conv_params += (self.filter_size * self.filter_size * in_channels + 1) * self.num_filters\n            # Batch norm parameters if enabled\n            if self.use_batch_norm:\n                conv_params += 2 * self.num_filters  # gamma and beta for each channel\n            in_channels = self.num_filters\n        \n        # Parameters in dense layers\n        dense_params = (self.flattened_size * self.dense_neurons + self.dense_neurons +  # first dense layer\n                       self.dense_neurons * 10 + 10)  # output layer\n        \n        return conv_params + dense_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T10:47:12.226520Z","iopub.execute_input":"2025-04-16T10:47:12.226897Z","iopub.status.idle":"2025-04-16T10:47:12.239035Z","shell.execute_reply.started":"2025-04-16T10:47:12.226876Z","shell.execute_reply":"2025-04-16T10:47:12.238474Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train(config=None):\n    # Initialize wandb\n    with wandb.init(config=config):\n        config = wandb.config\n        \n        # Set random seed for reproducibility\n        torch.manual_seed(config.seed)\n        np.random.seed(config.seed)\n        \n        # Data augmentation and normalization\n        train_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        val_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        # Load dataset\n        train_dataset = datasets.ImageFolder(\n            root='/kaggle/working/inaturalist_12K/train',\n            transform=train_transform\n        )\n        \n        # Split into train and validation\n        train_size = int(0.8 * len(train_dataset))\n        val_size = len(train_dataset) - train_size\n        \n        # Use stratified split to maintain class balance\n        train_indices, val_indices = train_test_split(\n            list(range(len(train_dataset))),\n            test_size=0.2,\n            stratify=train_dataset.targets,\n            random_state=config.seed\n        )\n        \n        train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n        val_subset = torch.utils.data.Subset(train_dataset, val_indices)\n        \n        train_loader = DataLoader(\n            train_subset,\n            batch_size=config.batch_size,\n            shuffle=True,\n            num_workers=4\n        )\n        \n        val_loader = DataLoader(\n            val_subset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=4\n        )\n        \n        # Initialize model\n        model = FlexibleCNN(\n            num_filters=config.num_filters,\n            filter_size=config.filter_size,\n            activation=config.activation,\n            dense_neurons=config.dense_neurons,\n            use_batch_norm=config.use_batch_norm,\n            dropout_rate=config.dropout_rate\n        )\n        \n        # Move model to GPU if available\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model = model.to(device)\n        \n        # Loss function and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n        \n        # Training loop\n        best_val_acc = 0\n        best_config = None\n        \n        for epoch in range(config.epochs):\n            # Training phase\n            model.train()\n            train_loss = 0\n            train_correct = 0\n            train_total = 0\n            \n            for batch_idx, (inputs, targets) in enumerate(train_loader):\n                inputs, targets = inputs.to(device), targets.to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                \n                train_loss += loss.item()\n                _, predicted = outputs.max(1)\n                train_total += targets.size(0)\n                train_correct += predicted.eq(targets).sum().item()\n                \n                if batch_idx % 100 == 0:\n                    print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n            \n            train_acc = 100. * train_correct / train_total\n            \n            # Validation phase\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            \n            with torch.no_grad():\n                for inputs, targets in val_loader:\n                    inputs, targets = inputs.to(device), targets.to(device)\n                    outputs = model(inputs)\n                    loss = criterion(outputs, targets)\n                    \n                    val_loss += loss.item()\n                    _, predicted = outputs.max(1)\n                    val_total += targets.size(0)\n                    val_correct += predicted.eq(targets).sum().item()\n            \n            val_acc = 100. * val_correct / val_total\n            \n            # Log metrics to wandb\n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": train_loss / len(train_loader),\n                \"train_acc\": train_acc,\n                \"val_loss\": val_loss / len(val_loader),\n                \"val_acc\": val_acc\n            })\n            \n            # Save best model\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model.state_dict(), 'best_model.pth')\n                best_config = dict(config)\n                with open('best_config.json', 'w') as f:\n                    json.dump(best_config, f, indent=4)\n            \n            print(f'Epoch: {epoch}, Train Loss: {train_loss/len(train_loader):.4f}, '\n                  f'Train Acc: {train_acc:.2f}%, Val Loss: {val_loss/len(val_loader):.4f}, '\n                  f'Val Acc: {val_acc:.2f}%')\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T10:47:12.239797Z","iopub.execute_input":"2025-04-16T10:47:12.240050Z","iopub.status.idle":"2025-04-16T10:47:12.263833Z","shell.execute_reply.started":"2025-04-16T10:47:12.240024Z","shell.execute_reply":"2025-04-16T10:47:12.263265Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\n# Define sweep configuration\nsweep_config = {\n    'method': 'bayes',  # Use Bayesian optimization\n    'metric': {\n        'name': 'val_acc',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'num_filters': {\n            'values': [32, 64, 128]\n        },\n        'filter_size': {\n            'values': [3, 5]\n        },\n        'activation': {\n            'values': ['relu', 'gelu', 'silu', 'mish']\n        },\n        'dense_neurons': {\n            'values': [256, 512]\n        },\n        'learning_rate': {\n            'min': 1e-4,\n            'max': 1e-2\n        },\n        'batch_size': {\n            'values': [32, 64, 128]\n        },\n        'use_batch_norm': {\n            'values': [True, False]\n        },\n        'dropout_rate': {\n            'values': [0.2, 0.3]\n        },\n        'epochs': {\n            'value': 10\n        },\n        'seed': {\n            'value': 42\n        }\n    }\n}\n\n# Initialize sweep\nsweep_id = wandb.sweep(sweep_config, project=\"inaturalist-cnn-sweep\")\n\n# Run sweep\nwandb.agent(sweep_id, train, count=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T10:47:12.264576Z","iopub.execute_input":"2025-04-16T10:47:12.264821Z","iopub.status.idle":"2025-04-16T11:56:42.201598Z","shell.execute_reply.started":"2025-04-16T10:47:12.264800Z","shell.execute_reply":"2025-04-16T11:56:42.201017Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: jd6qrw5v\nSweep URL: https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2z6ng4gy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00940026915207813\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_104719-2z6ng4gy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2z6ng4gy' target=\"_blank\">fragrant-sweep-1</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2z6ng4gy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2z6ng4gy</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.2800\nEpoch: 0, Batch: 100, Loss: 2.4687\nEpoch: 0, Batch: 200, Loss: 2.2802\nEpoch: 0, Train Loss: 2.5445, Train Acc: 12.74%, Val Loss: 2.2772, Val Acc: 18.15%\nEpoch: 1, Batch: 0, Loss: 2.3449\nEpoch: 1, Batch: 100, Loss: 2.2796\nEpoch: 1, Batch: 200, Loss: 2.2969\nEpoch: 1, Train Loss: 2.2838, Train Acc: 13.65%, Val Loss: 2.2484, Val Acc: 16.05%\nEpoch: 2, Batch: 0, Loss: 2.3252\nEpoch: 2, Batch: 100, Loss: 2.1895\nEpoch: 2, Batch: 200, Loss: 2.1537\nEpoch: 2, Train Loss: 2.2801, Train Acc: 14.55%, Val Loss: 2.2548, Val Acc: 17.20%\nEpoch: 3, Batch: 0, Loss: 2.2278\nEpoch: 3, Batch: 100, Loss: 2.2969\nEpoch: 3, Batch: 200, Loss: 2.3353\nEpoch: 3, Train Loss: 2.2588, Train Acc: 16.03%, Val Loss: 2.2247, Val Acc: 18.20%\nEpoch: 4, Batch: 0, Loss: 2.2223\nEpoch: 4, Batch: 100, Loss: 2.1784\nEpoch: 4, Batch: 200, Loss: 2.3226\nEpoch: 4, Train Loss: 2.2508, Train Acc: 16.29%, Val Loss: 2.2271, Val Acc: 18.90%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▃▅▇█</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>val_acc</td><td>▆▁▄▆█</td></tr><tr><td>val_loss</td><td>█▄▅▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>16.28954</td></tr><tr><td>train_loss</td><td>2.25078</td></tr><tr><td>val_acc</td><td>18.9</td></tr><tr><td>val_loss</td><td>2.22706</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fragrant-sweep-1</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2z6ng4gy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2z6ng4gy</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_104719-2z6ng4gy/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2buiji7e with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004889178320332993\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_105202-2buiji7e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2buiji7e' target=\"_blank\">grateful-sweep-2</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2buiji7e' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2buiji7e</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.4041\nEpoch: 0, Batch: 100, Loss: 2.2841\nEpoch: 0, Batch: 200, Loss: 2.2899\nEpoch: 0, Train Loss: 2.3586, Train Acc: 11.10%, Val Loss: 2.2718, Val Acc: 13.60%\nEpoch: 1, Batch: 0, Loss: 2.2699\nEpoch: 1, Batch: 100, Loss: 2.2526\nEpoch: 1, Batch: 200, Loss: 2.2935\nEpoch: 1, Train Loss: 2.2835, Train Acc: 12.36%, Val Loss: 2.2584, Val Acc: 14.20%\nEpoch: 2, Batch: 0, Loss: 2.2597\nEpoch: 2, Batch: 100, Loss: 2.2619\nEpoch: 2, Batch: 200, Loss: 2.2606\nEpoch: 2, Train Loss: 2.2833, Train Acc: 12.40%, Val Loss: 2.2689, Val Acc: 13.25%\nEpoch: 3, Batch: 0, Loss: 2.4298\nEpoch: 3, Batch: 100, Loss: 2.2702\nEpoch: 3, Batch: 200, Loss: 2.2144\nEpoch: 3, Train Loss: 2.2831, Train Acc: 12.01%, Val Loss: 2.2441, Val Acc: 14.35%\nEpoch: 4, Batch: 0, Loss: 2.3115\nEpoch: 4, Batch: 100, Loss: 2.2551\nEpoch: 4, Batch: 200, Loss: 2.2373\nEpoch: 4, Train Loss: 2.2721, Train Acc: 13.23%, Val Loss: 2.2400, Val Acc: 15.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▅▅▄█</td></tr><tr><td>train_loss</td><td>█▂▂▂▁</td></tr><tr><td>val_acc</td><td>▂▄▁▅█</td></tr><tr><td>val_loss</td><td>█▅▇▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>13.22665</td></tr><tr><td>train_loss</td><td>2.27206</td></tr><tr><td>val_acc</td><td>15.35</td></tr><tr><td>val_loss</td><td>2.23999</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-sweep-2</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2buiji7e' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2buiji7e</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_105202-2buiji7e/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0euh9md with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008128074299678444\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_105650-a0euh9md</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/a0euh9md' target=\"_blank\">cosmic-sweep-3</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/a0euh9md' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/a0euh9md</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3061\nEpoch: 0, Batch: 100, Loss: 2.3206\nEpoch: 0, Train Loss: 2.8751, Train Acc: 10.20%, Val Loss: 2.3039, Val Acc: 10.00%\nEpoch: 1, Batch: 0, Loss: 2.2875\nEpoch: 1, Batch: 100, Loss: 2.2989\nEpoch: 1, Train Loss: 2.5281, Train Acc: 9.75%, Val Loss: 2.3028, Val Acc: 10.00%\nEpoch: 2, Batch: 0, Loss: 2.3020\nEpoch: 2, Batch: 100, Loss: 2.3057\nEpoch: 2, Train Loss: 2.3166, Train Acc: 9.50%, Val Loss: 2.3029, Val Acc: 10.00%\nEpoch: 3, Batch: 0, Loss: 2.3036\nEpoch: 3, Batch: 100, Loss: 2.3024\nEpoch: 3, Train Loss: 2.3042, Train Acc: 9.44%, Val Loss: 2.3027, Val Acc: 10.00%\nEpoch: 4, Batch: 0, Loss: 2.3026\nEpoch: 4, Batch: 100, Loss: 2.3098\nEpoch: 4, Train Loss: 2.3044, Train Acc: 9.09%, Val Loss: 2.3030, Val Acc: 10.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>█▅▄▃▁</td></tr><tr><td>train_loss</td><td>█▄▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>9.08864</td></tr><tr><td>train_loss</td><td>2.30441</td></tr><tr><td>val_acc</td><td>10</td></tr><tr><td>val_loss</td><td>2.30298</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cosmic-sweep-3</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/a0euh9md' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/a0euh9md</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_105650-a0euh9md/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t89e4era with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008264428060302458\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_110128-t89e4era</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/t89e4era' target=\"_blank\">ethereal-sweep-4</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/t89e4era' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/t89e4era</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3846\nEpoch: 0, Batch: 100, Loss: 2.3125\nEpoch: 0, Batch: 200, Loss: 2.3196\nEpoch: 0, Train Loss: 2.5893, Train Acc: 11.44%, Val Loss: 2.3029, Val Acc: 10.40%\nEpoch: 1, Batch: 0, Loss: 2.3034\nEpoch: 1, Batch: 100, Loss: 2.3109\nEpoch: 1, Batch: 200, Loss: 2.3056\nEpoch: 1, Train Loss: 2.3458, Train Acc: 10.04%, Val Loss: 2.3027, Val Acc: 10.05%\nEpoch: 2, Batch: 0, Loss: 2.2958\nEpoch: 2, Batch: 100, Loss: 2.3145\nEpoch: 2, Batch: 200, Loss: 2.3087\nEpoch: 2, Train Loss: 2.3130, Train Acc: 9.66%, Val Loss: 2.3031, Val Acc: 10.00%\nEpoch: 3, Batch: 0, Loss: 2.3115\nEpoch: 3, Batch: 100, Loss: 2.3005\nEpoch: 3, Batch: 200, Loss: 2.2918\nEpoch: 3, Train Loss: 2.3068, Train Acc: 9.78%, Val Loss: 2.3035, Val Acc: 10.00%\nEpoch: 4, Batch: 0, Loss: 2.3089\nEpoch: 4, Batch: 100, Loss: 2.2959\nEpoch: 4, Batch: 200, Loss: 2.3103\nEpoch: 4, Train Loss: 2.3073, Train Acc: 9.46%, Val Loss: 2.3030, Val Acc: 10.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>█▃▂▂▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁</td></tr><tr><td>val_acc</td><td>█▂▁▁▁</td></tr><tr><td>val_loss</td><td>▂▁▄█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>9.46368</td></tr><tr><td>train_loss</td><td>2.30734</td></tr><tr><td>val_acc</td><td>10</td></tr><tr><td>val_loss</td><td>2.303</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ethereal-sweep-4</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/t89e4era' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/t89e4era</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_110128-t89e4era/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b1w0ihmz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008584913124099229\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_110622-b1w0ihmz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/b1w0ihmz' target=\"_blank\">super-sweep-5</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/b1w0ihmz' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/b1w0ihmz</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3307\nEpoch: 0, Train Loss: 2.3979, Train Acc: 14.15%, Val Loss: 2.2402, Val Acc: 19.85%\nEpoch: 1, Batch: 0, Loss: 2.2904\nEpoch: 1, Train Loss: 2.2223, Train Acc: 17.85%, Val Loss: 2.1664, Val Acc: 20.85%\nEpoch: 2, Batch: 0, Loss: 2.1728\nEpoch: 2, Train Loss: 2.1999, Train Acc: 19.89%, Val Loss: 2.1307, Val Acc: 22.25%\nEpoch: 3, Batch: 0, Loss: 2.1892\nEpoch: 3, Train Loss: 2.1731, Train Acc: 20.22%, Val Loss: 2.1172, Val Acc: 21.65%\nEpoch: 4, Batch: 0, Loss: 2.3127\nEpoch: 4, Train Loss: 2.1675, Train Acc: 20.42%, Val Loss: 2.1110, Val Acc: 22.80%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▅▇██</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▇▅█</td></tr><tr><td>val_loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>20.41505</td></tr><tr><td>train_loss</td><td>2.1675</td></tr><tr><td>val_acc</td><td>22.8</td></tr><tr><td>val_loss</td><td>2.111</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">super-sweep-5</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/b1w0ihmz' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/b1w0ihmz</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_110622-b1w0ihmz/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z8b6musr with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007733548209921999\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_111100-z8b6musr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/z8b6musr' target=\"_blank\">bumbling-sweep-6</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/z8b6musr' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/z8b6musr</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3238\nEpoch: 0, Train Loss: 2.6038, Train Acc: 12.88%, Val Loss: 2.2329, Val Acc: 16.15%\nEpoch: 1, Batch: 0, Loss: 2.2248\nEpoch: 1, Train Loss: 2.2541, Train Acc: 15.86%, Val Loss: 2.2014, Val Acc: 18.50%\nEpoch: 2, Batch: 0, Loss: 2.1745\nEpoch: 2, Train Loss: 2.2138, Train Acc: 18.00%, Val Loss: 2.1676, Val Acc: 21.15%\nEpoch: 3, Batch: 0, Loss: 2.2343\nEpoch: 3, Train Loss: 2.1790, Train Acc: 20.09%, Val Loss: 2.1543, Val Acc: 21.65%\nEpoch: 4, Batch: 0, Loss: 2.1554\nEpoch: 4, Train Loss: 2.1752, Train Acc: 20.20%, Val Loss: 2.1186, Val Acc: 21.75%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▄▆██</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▄▇██</td></tr><tr><td>val_loss</td><td>█▆▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>20.20253</td></tr><tr><td>train_loss</td><td>2.17524</td></tr><tr><td>val_acc</td><td>21.75</td></tr><tr><td>val_loss</td><td>2.11857</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bumbling-sweep-6</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/z8b6musr' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/z8b6musr</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_111100-z8b6musr/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7th0f5co with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008432123748848313\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_111539-7th0f5co</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/7th0f5co' target=\"_blank\">vague-sweep-7</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/7th0f5co' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/7th0f5co</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3340\nEpoch: 0, Batch: 100, Loss: 2.2596\nEpoch: 0, Train Loss: 2.5164, Train Acc: 11.81%, Val Loss: 2.2877, Val Acc: 12.60%\nEpoch: 1, Batch: 0, Loss: 2.2574\nEpoch: 1, Batch: 100, Loss: 2.4033\nEpoch: 1, Train Loss: 2.3012, Train Acc: 11.89%, Val Loss: 2.2723, Val Acc: 12.55%\nEpoch: 2, Batch: 0, Loss: 2.2660\nEpoch: 2, Batch: 100, Loss: 2.3168\nEpoch: 2, Train Loss: 2.3074, Train Acc: 12.45%, Val Loss: 2.2806, Val Acc: 9.90%\nEpoch: 3, Batch: 0, Loss: 2.3814\nEpoch: 3, Batch: 100, Loss: 2.2882\nEpoch: 3, Train Loss: 2.2847, Train Acc: 12.63%, Val Loss: 2.2696, Val Acc: 14.10%\nEpoch: 4, Batch: 0, Loss: 2.2662\nEpoch: 4, Batch: 100, Loss: 2.2303\nEpoch: 4, Train Loss: 2.2875, Train Acc: 13.18%, Val Loss: 2.2425, Val Acc: 16.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▁▄▅█</td></tr><tr><td>train_loss</td><td>█▁▂▁▁</td></tr><tr><td>val_acc</td><td>▄▄▁▆█</td></tr><tr><td>val_loss</td><td>█▆▇▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>13.17665</td></tr><tr><td>train_loss</td><td>2.28753</td></tr><tr><td>val_acc</td><td>16.25</td></tr><tr><td>val_loss</td><td>2.24249</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vague-sweep-7</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/7th0f5co' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/7th0f5co</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_111539-7th0f5co/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f4xxgvce with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00899280936056971\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_112017-f4xxgvce</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/f4xxgvce' target=\"_blank\">rich-sweep-8</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/f4xxgvce' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/f4xxgvce</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3051\nEpoch: 0, Train Loss: 2.5679, Train Acc: 12.79%, Val Loss: 2.2606, Val Acc: 15.65%\nEpoch: 1, Batch: 0, Loss: 2.2736\nEpoch: 1, Train Loss: 2.2841, Train Acc: 13.36%, Val Loss: 2.2579, Val Acc: 14.80%\nEpoch: 2, Batch: 0, Loss: 2.2700\nEpoch: 2, Train Loss: 2.2682, Train Acc: 15.13%, Val Loss: 2.2546, Val Acc: 16.40%\nEpoch: 3, Batch: 0, Loss: 2.2596\nEpoch: 3, Train Loss: 2.2650, Train Acc: 15.50%, Val Loss: 2.2133, Val Acc: 16.20%\nEpoch: 4, Batch: 0, Loss: 2.2878\nEpoch: 4, Train Loss: 2.2420, Train Acc: 15.60%, Val Loss: 2.1757, Val Acc: 18.30%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▂▇██</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>val_acc</td><td>▃▁▄▄█</td></tr><tr><td>val_loss</td><td>███▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>15.60195</td></tr><tr><td>train_loss</td><td>2.24195</td></tr><tr><td>val_acc</td><td>18.3</td></tr><tr><td>val_loss</td><td>2.17569</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rich-sweep-8</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/f4xxgvce' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/f4xxgvce</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_112017-f4xxgvce/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5rvt4g6x with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008681749680312954\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_112505-5rvt4g6x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5rvt4g6x' target=\"_blank\">glamorous-sweep-9</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5rvt4g6x' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5rvt4g6x</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3238\nEpoch: 0, Train Loss: 2.6567, Train Acc: 12.93%, Val Loss: 2.2573, Val Acc: 14.80%\nEpoch: 1, Batch: 0, Loss: 2.2802\nEpoch: 1, Train Loss: 2.2663, Train Acc: 14.89%, Val Loss: 2.2226, Val Acc: 16.35%\nEpoch: 2, Batch: 0, Loss: 2.2066\nEpoch: 2, Train Loss: 2.2383, Train Acc: 16.48%, Val Loss: 2.1759, Val Acc: 20.20%\nEpoch: 3, Batch: 0, Loss: 2.2543\nEpoch: 3, Train Loss: 2.2049, Train Acc: 18.95%, Val Loss: 2.1660, Val Acc: 21.30%\nEpoch: 4, Batch: 0, Loss: 2.1644\nEpoch: 4, Train Loss: 2.1879, Train Acc: 20.25%, Val Loss: 2.1364, Val Acc: 21.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▃▄▇█</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▇██</td></tr><tr><td>val_loss</td><td>█▆▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>20.25253</td></tr><tr><td>train_loss</td><td>2.1879</td></tr><tr><td>val_acc</td><td>21.5</td></tr><tr><td>val_loss</td><td>2.13642</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glamorous-sweep-9</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5rvt4g6x' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5rvt4g6x</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_112505-5rvt4g6x/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gduhwxxa with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009980261730379428\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_112949-gduhwxxa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/gduhwxxa' target=\"_blank\">autumn-sweep-10</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/gduhwxxa' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/gduhwxxa</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3060\nEpoch: 0, Train Loss: 3.2506, Train Acc: 10.03%, Val Loss: 2.3029, Val Acc: 10.00%\nEpoch: 1, Batch: 0, Loss: 2.5533\nEpoch: 1, Train Loss: 2.3533, Train Acc: 9.49%, Val Loss: 2.3027, Val Acc: 10.00%\nEpoch: 2, Batch: 0, Loss: 2.2887\nEpoch: 2, Train Loss: 2.3354, Train Acc: 9.94%, Val Loss: 2.3026, Val Acc: 10.00%\nEpoch: 3, Batch: 0, Loss: 2.3050\nEpoch: 3, Train Loss: 2.3108, Train Acc: 9.40%, Val Loss: 2.3026, Val Acc: 10.00%\nEpoch: 4, Batch: 0, Loss: 2.3031\nEpoch: 4, Train Loss: 2.3292, Train Acc: 9.58%, Val Loss: 2.3027, Val Acc: 10.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>█▂▇▁▃</td></tr><tr><td>train_loss</td><td>█▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>9.5762</td></tr><tr><td>train_loss</td><td>2.32918</td></tr><tr><td>val_acc</td><td>10</td></tr><tr><td>val_loss</td><td>2.30266</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">autumn-sweep-10</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/gduhwxxa' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/gduhwxxa</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_112949-gduhwxxa/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6kcjxx6j with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009527881149465765\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_113437-6kcjxx6j</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6kcjxx6j' target=\"_blank\">dauntless-sweep-11</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6kcjxx6j' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6kcjxx6j</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3111\nEpoch: 0, Train Loss: 3.0964, Train Acc: 12.03%, Val Loss: 2.2753, Val Acc: 14.35%\nEpoch: 1, Batch: 0, Loss: 2.3137\nEpoch: 1, Train Loss: 2.2500, Train Acc: 16.16%, Val Loss: 2.1682, Val Acc: 21.00%\nEpoch: 2, Batch: 0, Loss: 2.1866\nEpoch: 2, Train Loss: 2.2068, Train Acc: 19.09%, Val Loss: 2.1791, Val Acc: 20.20%\nEpoch: 3, Batch: 0, Loss: 2.2486\nEpoch: 3, Train Loss: 2.2073, Train Acc: 18.74%, Val Loss: 2.1586, Val Acc: 21.85%\nEpoch: 4, Batch: 0, Loss: 2.1736\nEpoch: 4, Train Loss: 2.2019, Train Acc: 19.70%, Val Loss: 2.1545, Val Acc: 22.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▅▇▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▇▆██</td></tr><tr><td>val_loss</td><td>█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>19.70246</td></tr><tr><td>train_loss</td><td>2.20186</td></tr><tr><td>val_acc</td><td>22.25</td></tr><tr><td>val_loss</td><td>2.15455</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dauntless-sweep-11</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6kcjxx6j' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6kcjxx6j</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_113437-6kcjxx6j/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3xt4txim with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009180143806767172\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_113927-3xt4txim</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/3xt4txim' target=\"_blank\">giddy-sweep-12</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/3xt4txim' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/3xt4txim</a>"},"metadata":{}},{"name":"stdout","text":"Epoch: 0, Batch: 0, Loss: 2.3123\nEpoch: 0, Train Loss: 3.3391, Train Acc: 11.01%, Val Loss: 2.2926, Val Acc: 11.45%\nEpoch: 1, Batch: 0, Loss: 2.3236\nEpoch: 1, Train Loss: 2.3107, Train Acc: 11.83%, Val Loss: 2.2795, Val Acc: 13.55%\nEpoch: 2, Batch: 0, Loss: 2.2712\nEpoch: 2, Train Loss: 2.2894, Train Acc: 13.74%, Val Loss: 2.2292, Val Acc: 16.40%\nEpoch: 3, Batch: 0, Loss: 2.2462\nEpoch: 3, Train Loss: 2.2566, Train Acc: 15.04%, Val Loss: 2.2061, Val Acc: 17.85%\nEpoch: 4, Batch: 0, Loss: 2.2071\nEpoch: 4, Train Loss: 2.2702, Train Acc: 13.38%, Val Loss: 2.2316, Val Acc: 15.20%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▂▆█▅</td></tr><tr><td>train_loss</td><td>█▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▆█▅</td></tr><tr><td>val_loss</td><td>█▇▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>13.37667</td></tr><tr><td>train_loss</td><td>2.27021</td></tr><tr><td>val_acc</td><td>15.2</td></tr><tr><td>val_loss</td><td>2.23161</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">giddy-sweep-12</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/3xt4txim' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/3xt4txim</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_113927-3xt4txim/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 10vnrema with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009829871947680134\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114416-10vnrema</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/10vnrema' target=\"_blank\">ruby-sweep-13</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/10vnrema' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/10vnrema</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 98, in train\n    loss.backward()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n    torch.autograd.backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n    _engine_run_backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 173.12 MiB is free. Process 2366 has 15.72 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 200.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ruby-sweep-13</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/10vnrema' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/10vnrema</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114416-10vnrema/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 10vnrema errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 98, in train\n    loss.backward()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n    torch.autograd.backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n    _engine_run_backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 173.12 MiB is free. Process 2366 has 15.72 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 200.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 10vnrema errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 98, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss.backward()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.autograd.backward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _engine_run_backward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 173.12 MiB is free. Process 2366 has 15.72 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 200.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s27zq2vp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007045364843004526\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114437-s27zq2vp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/s27zq2vp' target=\"_blank\">divine-sweep-14</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/s27zq2vp' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/s27zq2vp</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 221.12 MiB is free. Process 2366 has 15.67 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 121.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">divine-sweep-14</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/s27zq2vp' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/s27zq2vp</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114437-s27zq2vp/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run s27zq2vp errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 221.12 MiB is free. Process 2366 has 15.67 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 121.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run s27zq2vp errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(inputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = block(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 221.12 MiB is free. Process 2366 has 15.67 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 121.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tphrbi5k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006628665853365329\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114458-tphrbi5k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/tphrbi5k' target=\"_blank\">copper-sweep-15</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/tphrbi5k' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/tphrbi5k</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 147.12 MiB is free. Process 2366 has 15.74 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 113.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">copper-sweep-15</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/tphrbi5k' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/tphrbi5k</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114458-tphrbi5k/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run tphrbi5k errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 147.12 MiB is free. Process 2366 has 15.74 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 113.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run tphrbi5k errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(inputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = block(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 147.12 MiB is free. Process 2366 has 15.74 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 113.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rvunonzn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00991340302911777\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114519-rvunonzn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/rvunonzn' target=\"_blank\">ethereal-sweep-16</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/rvunonzn' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/rvunonzn</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 71.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 102.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ethereal-sweep-16</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/rvunonzn' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/rvunonzn</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114519-rvunonzn/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run rvunonzn errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 71.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 102.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run rvunonzn errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(inputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = block(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 0 has a total capacity of 15.89 GiB of which 71.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 102.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9gs7uoa9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006927242569675713\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114540-9gs7uoa9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9gs7uoa9' target=\"_blank\">silvery-sweep-17</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9gs7uoa9' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9gs7uoa9</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 71.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 98.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silvery-sweep-17</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9gs7uoa9' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9gs7uoa9</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114540-9gs7uoa9/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 9gs7uoa9 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 71.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 98.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 9gs7uoa9 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 71.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 98.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6hiqsqwe with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00401631074452203\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114600-6hiqsqwe</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6hiqsqwe' target=\"_blank\">rural-sweep-18</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6hiqsqwe' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6hiqsqwe</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 69.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.44 GiB is allocated by PyTorch, and 75.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rural-sweep-18</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6hiqsqwe' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/6hiqsqwe</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114600-6hiqsqwe/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 6hiqsqwe errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 69.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.44 GiB is allocated by PyTorch, and 75.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 6hiqsqwe errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(inputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = block(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 69.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.44 GiB is allocated by PyTorch, and 75.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 779wzenk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00017865048572233793\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114622-779wzenk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/779wzenk' target=\"_blank\">wise-sweep-19</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/779wzenk' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/779wzenk</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 67.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 50.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wise-sweep-19</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/779wzenk' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/779wzenk</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114622-779wzenk/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 779wzenk errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 67.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 50.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 779wzenk errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(inputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = block(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 67.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.47 GiB is allocated by PyTorch, and 50.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 303iy83m with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00622758527705171\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114643-303iy83m</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/303iy83m' target=\"_blank\">comfy-sweep-20</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/303iy83m' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/303iy83m</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 65.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 7.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">comfy-sweep-20</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/303iy83m' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/303iy83m</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114643-303iy83m/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 303iy83m errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n    outputs = model(inputs)\n              ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n    x = block(x)\n        ^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n    return F.conv2d(\n           ^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 65.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 7.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 303iy83m errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 96, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(inputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/1310665857.py\", line 73, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = block(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 65.12 MiB is free. Process 2366 has 15.82 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 7.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0qj4g7qd with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00593284345917001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114709-0qj4g7qd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0qj4g7qd' target=\"_blank\">efficient-sweep-21</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0qj4g7qd' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0qj4g7qd</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 45.12 MiB is free. Process 2366 has 15.84 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 14.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">efficient-sweep-21</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0qj4g7qd' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0qj4g7qd</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114709-0qj4g7qd/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 0qj4g7qd errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 45.12 MiB is free. Process 2366 has 15.84 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 14.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0qj4g7qd errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 45.12 MiB is free. Process 2366 has 15.84 GiB memory in use. Of the allocated memory 15.53 GiB is allocated by PyTorch, and 14.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ay6fqk40 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008351380830867396\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114730-ay6fqk40</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ay6fqk40' target=\"_blank\">hearty-sweep-22</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ay6fqk40' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ay6fqk40</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 43.12 MiB is free. Process 2366 has 15.84 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 3.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">hearty-sweep-22</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ay6fqk40' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ay6fqk40</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114730-ay6fqk40/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ay6fqk40 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 43.12 MiB is free. Process 2366 has 15.84 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 3.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ay6fqk40 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 43.12 MiB is free. Process 2366 has 15.84 GiB memory in use. Of the allocated memory 15.54 GiB is allocated by PyTorch, and 3.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: olyc4qpx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0019190223259563008\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114751-olyc4qpx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/olyc4qpx' target=\"_blank\">misty-sweep-23</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/olyc4qpx' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/olyc4qpx</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 23.12 MiB is free. Process 2366 has 15.86 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 16.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">misty-sweep-23</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/olyc4qpx' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/olyc4qpx</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114751-olyc4qpx/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run olyc4qpx errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 23.12 MiB is free. Process 2366 has 15.86 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 16.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run olyc4qpx errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 23.12 MiB is free. Process 2366 has 15.86 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 16.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ma6agjsv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006968462238463182\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114812-ma6agjsv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ma6agjsv' target=\"_blank\">peachy-sweep-24</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ma6agjsv' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ma6agjsv</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 16.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">peachy-sweep-24</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ma6agjsv' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ma6agjsv</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114812-ma6agjsv/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ma6agjsv errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 16.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ma6agjsv errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 16.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ezrqa692 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0012439971969980803\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114828-ezrqa692</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ezrqa692' target=\"_blank\">expert-sweep-25</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ezrqa692' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ezrqa692</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">expert-sweep-25</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ezrqa692' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ezrqa692</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114828-ezrqa692/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ezrqa692 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ezrqa692 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.55 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vxaml2m2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005285047806742348\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114853-vxaml2m2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vxaml2m2' target=\"_blank\">hearty-sweep-26</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vxaml2m2' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vxaml2m2</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">hearty-sweep-26</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vxaml2m2' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vxaml2m2</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114853-vxaml2m2/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run vxaml2m2 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run vxaml2m2 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ejr2os6o with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00987995373013559\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114910-ejr2os6o</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ejr2os6o' target=\"_blank\">leafy-sweep-27</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ejr2os6o' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ejr2os6o</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">leafy-sweep-27</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ejr2os6o' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ejr2os6o</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114910-ejr2os6o/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ejr2os6o errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ejr2os6o errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ecyqe27 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005707222639712002\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114935-0ecyqe27</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0ecyqe27' target=\"_blank\">ruby-sweep-28</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0ecyqe27' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0ecyqe27</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ruby-sweep-28</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0ecyqe27' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0ecyqe27</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114935-0ecyqe27/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 0ecyqe27 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0ecyqe27 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 9.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 41h5t0n5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008417940735823796\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_114952-41h5t0n5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/41h5t0n5' target=\"_blank\">drawn-sweep-29</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/41h5t0n5' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/41h5t0n5</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">drawn-sweep-29</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/41h5t0n5' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/41h5t0n5</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_114952-41h5t0n5/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 41h5t0n5 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n    inputs, targets = inputs.to(device), targets.to(device)\n                      ^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 41h5t0n5 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 93, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2us6t9mb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009446593217063265\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115014-2us6t9mb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2us6t9mb' target=\"_blank\">magic-sweep-30</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2us6t9mb' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2us6t9mb</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">magic-sweep-30</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2us6t9mb' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2us6t9mb</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115014-2us6t9mb/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 2us6t9mb errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2us6t9mb errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ile0clbm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009657008117402404\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115039-ile0clbm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ile0clbm' target=\"_blank\">valiant-sweep-31</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ile0clbm' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ile0clbm</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">valiant-sweep-31</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ile0clbm' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ile0clbm</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115039-ile0clbm/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ile0clbm errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ile0clbm errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1w1kzxvo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002054245049433838\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115055-1w1kzxvo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1w1kzxvo' target=\"_blank\">sunny-sweep-32</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1w1kzxvo' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1w1kzxvo</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sunny-sweep-32</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1w1kzxvo' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1w1kzxvo</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115055-1w1kzxvo/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 1w1kzxvo errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1w1kzxvo errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2a6ifiey with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0057079558217045115\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115111-2a6ifiey</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2a6ifiey' target=\"_blank\">unique-sweep-33</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2a6ifiey' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2a6ifiey</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">unique-sweep-33</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2a6ifiey' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2a6ifiey</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115111-2a6ifiey/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 2a6ifiey errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2a6ifiey errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4d8rddv2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004410177202701239\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115137-4d8rddv2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/4d8rddv2' target=\"_blank\">sage-sweep-34</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/4d8rddv2' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/4d8rddv2</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sage-sweep-34</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/4d8rddv2' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/4d8rddv2</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115137-4d8rddv2/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 4d8rddv2 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 4d8rddv2 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2vg97bxm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0060362052829627585\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115153-2vg97bxm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2vg97bxm' target=\"_blank\">eager-sweep-35</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2vg97bxm' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2vg97bxm</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eager-sweep-35</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2vg97bxm' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2vg97bxm</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115153-2vg97bxm/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 2vg97bxm errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2vg97bxm errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yyinhyqm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003537256832114589\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115219-yyinhyqm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/yyinhyqm' target=\"_blank\">rural-sweep-36</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/yyinhyqm' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/yyinhyqm</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rural-sweep-36</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/yyinhyqm' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/yyinhyqm</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115219-yyinhyqm/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run yyinhyqm errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run yyinhyqm errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ch1io4s9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011841529312659083\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115236-ch1io4s9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ch1io4s9' target=\"_blank\">devout-sweep-37</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ch1io4s9' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ch1io4s9</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">devout-sweep-37</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ch1io4s9' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ch1io4s9</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115236-ch1io4s9/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ch1io4s9 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ch1io4s9 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5su0qrp7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011579387847004228\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115252-5su0qrp7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5su0qrp7' target=\"_blank\">wise-sweep-38</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5su0qrp7' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5su0qrp7</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wise-sweep-38</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5su0qrp7' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/5su0qrp7</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115252-5su0qrp7/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 5su0qrp7 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5su0qrp7 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eoiblkow with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008064765593855813\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115308-eoiblkow</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/eoiblkow' target=\"_blank\">absurd-sweep-39</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/eoiblkow' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/eoiblkow</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">absurd-sweep-39</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/eoiblkow' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/eoiblkow</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115308-eoiblkow/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run eoiblkow errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run eoiblkow errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 070pxfro with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003124194151409493\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115323-070pxfro</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/070pxfro' target=\"_blank\">earnest-sweep-40</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/070pxfro' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/070pxfro</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">earnest-sweep-40</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/070pxfro' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/070pxfro</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115323-070pxfro/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 070pxfro errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 070pxfro errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lllxnev9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006600401024286831\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115339-lllxnev9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/lllxnev9' target=\"_blank\">glad-sweep-41</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/lllxnev9' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/lllxnev9</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glad-sweep-41</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/lllxnev9' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/lllxnev9</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115339-lllxnev9/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run lllxnev9 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run lllxnev9 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cl8ylrom with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00253969112697398\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115356-cl8ylrom</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/cl8ylrom' target=\"_blank\">rosy-sweep-42</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/cl8ylrom' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/cl8ylrom</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rosy-sweep-42</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/cl8ylrom' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/cl8ylrom</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115356-cl8ylrom/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run cl8ylrom errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run cl8ylrom errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2q30esgy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004200832724920716\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115412-2q30esgy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2q30esgy' target=\"_blank\">jolly-sweep-43</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2q30esgy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2q30esgy</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jolly-sweep-43</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2q30esgy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/2q30esgy</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115412-2q30esgy/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 2q30esgy errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2q30esgy errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1q530kzy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003317635560291156\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115427-1q530kzy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1q530kzy' target=\"_blank\">major-sweep-44</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1q530kzy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1q530kzy</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">major-sweep-44</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1q530kzy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/1q530kzy</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115427-1q530kzy/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 1q530kzy errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1q530kzy errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vi0t9kz5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0038764693180868377\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115444-vi0t9kz5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vi0t9kz5' target=\"_blank\">royal-sweep-45</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vi0t9kz5' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vi0t9kz5</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">royal-sweep-45</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vi0t9kz5' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/vi0t9kz5</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115444-vi0t9kz5/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run vi0t9kz5 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run vi0t9kz5 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0gj19vg3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00831653480484459\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115509-0gj19vg3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0gj19vg3' target=\"_blank\">light-sweep-46</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0gj19vg3' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0gj19vg3</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">light-sweep-46</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0gj19vg3' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/0gj19vg3</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115509-0gj19vg3/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 0gj19vg3 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0gj19vg3 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9sbcaaf3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002768582094708361\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115526-9sbcaaf3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9sbcaaf3' target=\"_blank\">gallant-sweep-47</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9sbcaaf3' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9sbcaaf3</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gallant-sweep-47</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9sbcaaf3' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/9sbcaaf3</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115526-9sbcaaf3/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 9sbcaaf3 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 9sbcaaf3 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j3g0xgcp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009527929160872693\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115551-j3g0xgcp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/j3g0xgcp' target=\"_blank\">effortless-sweep-48</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/j3g0xgcp' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/j3g0xgcp</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">effortless-sweep-48</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/j3g0xgcp' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/j3g0xgcp</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115551-j3g0xgcp/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run j3g0xgcp errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run j3g0xgcp errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hx35atxy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005868167760359567\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115607-hx35atxy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/hx35atxy' target=\"_blank\">rare-sweep-49</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/hx35atxy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/hx35atxy</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rare-sweep-49</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/hx35atxy' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/hx35atxy</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115607-hx35atxy/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run hx35atxy errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run hx35atxy errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ocis9t6d with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006736391499511936\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_batch_norm: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_115633-ocis9t6d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ocis9t6d' target=\"_blank\">vocal-sweep-50</a></strong> to <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/sweeps/jd6qrw5v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ocis9t6d' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ocis9t6d</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vocal-sweep-50</strong> at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ocis9t6d' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep/runs/ocis9t6d</a><br> View project at: <a href='https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep' target=\"_blank\">https://wandb.ai/da24m004-iitmaana/inaturalist-cnn-sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_115633-ocis9t6d/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ocis9t6d errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n    model = model.to(device)\n            ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n    return t.to(\n           ^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ocis9t6d errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2283347234.py\", line 75, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model.to(device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 2366 has 15.87 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 7.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data augmentation and normalization\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                      std=[0.229, 0.224, 0.225])\n])\n\n# Load dataset\ntest_dataset = datasets.ImageFolder(\n    root='/kaggle/working/inaturalist_12K/val',\n    transform=train_transform\n)\n\n# Split into train and validation\ntest_size = int(len(test_dataset))\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=config.batch_size,\n    shuffle=True,\n    num_workers=4\n)\n\nwith open('/kaggle/working/best_config.json', 'r') as f:\n    config = json.load(f)\n\n# Initialize model\nmodel = FlexibleCNN(\n    num_filters=config.num_filters,\n    filter_size=config.filter_size,\n    activation=config.activation,\n    dense_neurons=config.dense_neurons,\n    use_batch_norm=config.use_batch_norm,\n    dropout_rate=config.dropout_rate\n)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# /kaggle/working/inaturalist_12K/train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:13:41.289828Z","iopub.execute_input":"2025-04-15T16:13:41.290214Z","iopub.status.idle":"2025-04-15T16:13:41.294748Z","shell.execute_reply.started":"2025-04-15T16:13:41.290187Z","shell.execute_reply":"2025-04-15T16:13:41.293842Z"}},"outputs":[],"execution_count":39}]}